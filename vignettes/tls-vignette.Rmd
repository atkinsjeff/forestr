---
title: "TLS with process_tls"
author: "Jeff Atkins"
date: '`r Sys.Date()`'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TLS with process_tls}
  %\VignetteEngine{knitr::rmarkdown} 
  \usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette is aimed at those working with terrestrial LiDAR scanners (TLS). TLS systems collect high-resolution spherically projected range images from one or multiple stationary scan locations. Occlusion of vegetation is minimized when multiple scan locations are aligned and combined using artificial registration targets (Cifuentes et al. 2014). TLS data are commonly converted into x,y,z or ASCII format with each row representing the individual Cartesian coordinate and return intensity of a single LiDAR return. 

, the z-dimension of TLS data represents true topographic variation, rather than relative height above the instrument, necessitating normalization of TLS height data prior to processing with forestr.  Topographic variation is removed by creating a digital terrain model (DTM) of the ground returns and subsequently subtracting the DTM elevation values at each x, y coordinate from the z coordinates of the TLS data (Calders et al., 2014). This process can be completed with any air-borne LiDAR analysis suite capable of normalizing the LiDAR point cloud to the ground surface (e.g., [Fusion LDTK](http://forsys.cfr.washington.edu/fusion/fusionlatest.html) or [Cloud Compare](http://www.danielgm.net/cc/). At this stage of processing, all ground points are removed through a simple height dependent cutoff equivalent to the LiDAR sensor height above the forest floor.

Prior to processing with forestr, the topographically normalized TLS data are filtered to a consistent return density through voxelization. Voxelization superimposes a 3-D grid of a specified size on the point cloud and shifts all points falling within each individual cube to the center of the nearest cubic center. Equations for this are outlined in appendix one of Atkins et al. (In Review). Pre-processed TLS data are similarly in ASCII format with each corresponding coordinate representative of the location in space of 1 m voxels and filtered return density.

This vignette will walk you through how to analyze a PCL or portable canopy LiDAR file in two ways: 1) an automated way using the `process_pcl()` function, and 2) by processing the file step-by-step.

The `process_pcl()` function has the advantage that all of the output from the file is written to disk in an output directory that is created in the working directory which you can access via `getwd()` in your console. Approaching the problem step-by-step allows you to keep sections of the process in the workspace, but is more cumbersome and is not recommended as all relevant files are written to the output directory and can be worked with seperatly if so desired. 

TLS data are imported using the process_tls function. VAI in TLS data must be processed outside of forestr as outlined previously due to inherent issues with each instrument. `process_tls` takes an x, y, zÂ¸ VAI format as input with x and y describing the ground position and z describing the height above the ground. VAI then is the VAI for each voxel described by the x, y, z position.

## Using `process_tls`

After TLS data have been processed via the outline in appendix one, they CSC metrics can be calculated via the `process_tls`. Some CSC metrics are not yet availble via `forestr` for TLS data yet, but are underdevelopment, with encouragement for contributions from the community. A TSL example using the UVA data set contained in the `forestr` package within `data-raw`.


* `marker.spacing` is the distance between markers in the dataset (default is 10 meters). In PCL data, data markers which are default values below -9999 in the code, indicate the end of defined sections along the transect. 
* `user_height` is the offset, based on the user's own height differences and directly refers to the distance of the front portion of the laser from the ground. The value is added to all the distances in the data set.
* `max.vai` is the maximum vegetation area index at the 1 x 1 meter scale that is used to adjust sections of the data under saturated conditions (i.e. when the LiDAR fails to penetrate the canopy and records only canopy hits). A default value of 8 is used and has been found to be well-representative for a broad selection of forests.
* `pavd` and `hist` refers to the plant area volume density graph with histogram option. If `pavd` is set to TRUE, a plot will be written to the output folder. If `hist` is set to TRUE, a histogram will be superimposed over the PAVD curve.

The `process_pcl()` function will print multiple CSC metrics to the screen, including canopy rugosity, rumple, porosity, etc., but will also create an output directory named output within the working directory where it will store four things:

1.  The Summary Matrix - a .csv file of columnar values of mean leaf heigh, maximum height, vegetation area index (VAI), etc.
2.  The Hit Matrix - a .csv file containing VAI by rows where each row correpsonds to the x, z position of VAI in the canopy.
3.  The Output File - this is a .csv file that contains all CSC metrics in output form.
4.  The Hit Grid - this is a PNG image file of the vertical hit grid as explained in Hardiman et al. (2013) and is a graphic representation of the vertical distribution of leaf density throughout the canopy. This can be recreated and modified using the source code with the Hit Matrix file as the input.

```{r pcl-tls}
# Link to stored, raw PCL data in .csv form
uva.tls <- "https://raw.githubusercontent.com/atkinsjeff/forestr/master/data-raw/UVAX_A401_tls.csv" 

# Run process complete PCL transect, store output to disk
process_tls(uva.tls, slice = 20, pavd = TRUE, hist = TRUE)
```


![A plant area volume density plot](pavd.png){width=500px}

![A plant area volume density plot with histogram](pavd_hist.png){width=500px}


